{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "project_dir = 'C:/Users/zyt/Documents/GitHub Repositories/codeclf_gui/codeclf'\n",
    "sys.path.append(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from utils.CodeTokenizer import CodeTokenizer, CodeSplitTokenizer\n",
    "from utils.CodeTokenizer import ContextCodeTokenizer, ContextCodeSplitTokenizer\n",
    "from utils.Utils import timethis\n",
    "from preprocessing.DataProcessor import DataProcessor\n",
    "from train.ClfModel import ContextModel\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def feature_to_id_bta(features, label):\n",
    "    return ccst.from_feature_to_token_id_bta(features[0].decode(\"utf-8\"),\n",
    "                                            features[1].decode(\"utf-8\"),\n",
    "                                            features[2].decode(\"utf-8\")), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def tf_feature_to_id_bta(features, label):\n",
    "    label_shape = label.shape\n",
    "    [features, label] = tf.numpy_function(feature_to_id_bta,\n",
    "                                inp=[features, label],\n",
    "                                Tout=[tf.int32, tf.int64])\n",
    "    features.set_shape((60,))\n",
    "    label.set_shape(label_shape)\n",
    "    return features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_codes:330684, df_docs:192157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((3,), ()), types: (tf.string, tf.int64)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 未平衡两类别\n",
    "ccst = ContextCodeSplitTokenizer(os.path.join(project_dir, 'vocabs/split_simple_vocab50000.txt'))\n",
    "dp = DataProcessor()\n",
    "\n",
    "corpus_path = '../datasets/df_test_corpus.tar.bz2'\n",
    "df_data = pd.read_pickle(corpus_path)\n",
    "data = df_data['code']\n",
    "ds = dp.process_context_tfdata_merge(data)  # 自动标注\n",
    "\n",
    "ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((60,), ()), types: (tf.int32, tf.int64)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_test = ds.map(tf_feature_to_id_bta)\n",
    "ds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000001690D6AB7B8> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "    .filter(lambda features, label: label == 0).shuffle(100000).repeat())\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000001690D6AB7B8> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "    .filter(lambda features, label: label == 0).shuffle(100000).repeat())\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000001690D6AB7B8> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "    .filter(lambda features, label: label == 0).shuffle(100000).repeat())\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x00000169313EFA60> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "    .filter(lambda features, label: label == 1).shuffle(100000).repeat())\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x00000169313EFA60> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "    .filter(lambda features, label: label == 1).shuffle(100000).repeat())\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function <lambda> at 0x00000169313EFA60> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "    .filter(lambda features, label: label == 1).shuffle(100000).repeat())\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "# 平衡两类别\n",
    "test_code_ds = (ds_test\n",
    "    .filter(lambda features, label: label == 0).shuffle(100000).repeat())\n",
    "test_docs_ds = (ds_test\n",
    "    .filter(lambda features, label: label == 1).shuffle(100000).repeat())\n",
    "ds_test = tf.data.experimental.sample_from_datasets(\n",
    "            [test_code_ds, test_docs_ds],\n",
    "            weights=[0.5, 0.5])\n",
    "# ds_test = ds_test.shuffle(10000).batch(32).prefetch(2)\n",
    "ds_test = ds_test.batch(1024).prefetch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 19\n"
     ]
    }
   ],
   "source": [
    "count_code = 0\n",
    "count_docs = 0\n",
    "for f, l in ds_test.take(1):\n",
    "    # print(f, l)\n",
    "    for label in l:\n",
    "        if label == 0:\n",
    "            count_code += 1\n",
    "        else:\n",
    "            count_docs += 1\n",
    "print(count_code, count_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for f, l in ds_test.take(10):\n",
    "    # print(f, l)\n",
    "    print(l.numpy().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test context model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:loading training data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limiting training dataset: 20000\n",
      "df_codes:299858, df_docs:169993\n",
      "df_codes:313930, df_docs:195969\n",
      "WARNING:tensorflow:AutoGraph could not transform <function ContextModel.load_datasets.<locals>.<lambda> at 0x0000012E8B2B1158> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "            .filter(lambda features, label: label == 0)\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function ContextModel.load_datasets.<locals>.<lambda> at 0x0000012E8B2B1158> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "            .filter(lambda features, label: label == 0)\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function ContextModel.load_datasets.<locals>.<lambda> at 0x0000012E8B2B1158> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "            .filter(lambda features, label: label == 0)\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function ContextModel.load_datasets.<locals>.<lambda> at 0x0000012EDAC65E18> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "            .filter(lambda features, label: label == 1)\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function ContextModel.load_datasets.<locals>.<lambda> at 0x0000012EDAC65E18> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "            .filter(lambda features, label: label == 1)\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function ContextModel.load_datasets.<locals>.<lambda> at 0x0000012EDAC65E18> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "            .filter(lambda features, label: label == 1)\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:load_datasets executing time: 35.828125s\n",
      "INFO:root:datasets ready!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 90, 200)           10001200  \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 100)               100400    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 10,103,641\n",
      "Trainable params: 10,103,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trainer = ContextModel(before=1, after=1)\n",
    "trainer.load_vocab('../vocabs/nosplit_keyword_vocab50000.txt')\n",
    "\n",
    "logging.info('loading training data...')\n",
    "trainer.load_datasets(train_path='../datasets/df_train_corpus.tar.bz2',\n",
    "                      valid_path='../datasets/df_valid_corpus.tar.bz2',\n",
    "                      limit_dataset=20000)\n",
    "\n",
    "logging.info('datasets ready!')\n",
    "trainer.construct_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:start training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint detected, loading the model...\n",
      "Epoch 1/15\n"
     ]
    }
   ],
   "source": [
    "logging.info('start training...')\n",
    "trainer.train_model(checkpoint_save_path='../checkpoint/lstm_model_token_50000_context_try_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('saving model...')\n",
    "trainer.save_model('../models/lstm_model_token_50000_context_try_1.hdf5')\n",
    "\n",
    "trainer.plot_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('evaluating model...')\n",
    "trainer.evaluate(test_path='../datasets/df_test_corpus.tar.bz2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
